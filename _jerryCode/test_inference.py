import os
import cv2
import numpy as np
import time

# === è·¯å¾„é…ç½® ===
# MODEL_PATH = "model/yolov5n_960p_simplify.onnx"
MODEL_PATH = "model/yolov5n_960p.onnx"
INPUT_DIR = "resources/camera_sim"
OUTPUT_DIR = "resources/result"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# === åŠ è½½æ¨¡å‹ ===
net = cv2.dnn.readNetFromONNX(MODEL_PATH)

# === åå¤„ç†å‡½æ•° ===
def postprocess(outputs, image, conf_thresh=0.4):
    boxes, class_ids, confidences = [], [], []

    for i in range(outputs.shape[1]):
        row = outputs[0][i]
        confidence = row[4]
        if confidence > conf_thresh:
            scores = row[5:]
            class_id = np.argmax(scores)
            if scores[class_id] > conf_thresh:
                cx, cy, w, h = row[:4]
                left = int((cx - w/2) * image.shape[1] / 960)
                top = int((cy - h/2) * image.shape[0] / 960)
                width = int(w * image.shape[1] / 960)
                height = int(h * image.shape[0] / 960)

                boxes.append([left, top, width, height])
                class_ids.append(class_id)
                confidences.append(float(confidence))

    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, 0.5)
    if len(indices) == 0:
        return image

    for i in indices:
        idx = i[0] if isinstance(i, (list, tuple, np.ndarray)) else i
        box = boxes[idx]
        label = f"ID:{class_ids[idx]} {confidences[idx]:.2f}"
        cv2.rectangle(image, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), (0,255,0), 2)
        cv2.putText(image, label, (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

    return image

# === è·å–å›¾åƒåˆ—è¡¨ ===
image_files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# === ç»Ÿè®¡æ€»æ—¶é•¿å˜é‡ ===
total_read_time = 0
total_pre_time = 0
total_infer_time = 0
total_post_time = 0
total_count = len(image_files)

print(f"ğŸ“‚ å…±å‡†å¤‡æ¨ç† {total_count} å¼ å›¾åƒ...")

# === ä¸»å¤„ç†å¾ªç¯ ===
for file_name in image_files:
    t0 = time.time()
    image_path = os.path.join(INPUT_DIR, file_name)
    image = cv2.imread(image_path)
    t1 = time.time()
    resized = cv2.resize(image, (960, 960))
    blob = cv2.dnn.blobFromImage(resized, 1/255.0, (960, 960), swapRB=True, crop=False)
    t2 = time.time()
    net.setInput(blob)
    outputs = net.forward()
    t3 = time.time()
    result = postprocess(outputs, image)
    output_path = os.path.join(OUTPUT_DIR, f"det_{file_name}")
    cv2.imwrite(output_path, result)
    t4 = time.time()

    # åˆ†é˜¶æ®µè€—æ—¶ç»Ÿè®¡
    read_time = t1 - t0
    pre_time = t2 - t1
    infer_time = t3 - t2
    post_time = t4 - t3

    total_read_time += read_time
    total_pre_time += pre_time
    total_infer_time += infer_time
    total_post_time += post_time

    print(f"âœ… {file_name} | è¯»å–: {read_time:.3f}s | é¢„å¤„ç†: {pre_time:.3f}s | æ¨ç†: {infer_time:.3f}s | åå¤„ç†: {post_time:.3f}s")

# === å¹³å‡è€—æ—¶ç»Ÿè®¡ ===
print("\nğŸ“Š å¤„ç†å®Œæˆï¼å¹³å‡æ¯å¼ å›¾åƒè€—æ—¶ï¼š")
print(f"ğŸ“¥ å›¾åƒè¯»å–       : {total_read_time / total_count:.3f} ç§’")
print(f"ğŸ”§ å›¾åƒé¢„å¤„ç†     : {total_pre_time / total_count:.3f} ç§’")
print(f"ğŸ§  æ¨¡å‹æ¨ç†       : {total_infer_time / total_count:.3f} ç§’")
print(f"ğŸ–¼ï¸ ç»“æœåå¤„ç†ä¿å­˜ : {total_post_time / total_count:.3f} ç§’")
print(f"â±ï¸ å¹³å‡æ€»è€—æ—¶     : {(total_read_time + total_pre_time + total_infer_time + total_post_time) / total_count:.3f} ç§’")
